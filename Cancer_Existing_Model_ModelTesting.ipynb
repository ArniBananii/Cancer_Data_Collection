{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T23:51:38.747113Z",
     "start_time": "2025-05-14T23:50:32.359337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "model_benchmark.py – Version 1.2\n",
    "================================\n",
    "Ein lauffähiges Script, das verschiedene CNN-Architekturen fair vergleicht.\n",
    "– Train/Val/Test-Split ohne Leak\n",
    "– Sampler für Klassenbalance\n",
    "– ImageNet- oder Dataset-Norm abhängig vom Pfad (Fine-Tune vs. Scratch)\n",
    "– micro- und macro-F1\n",
    "– Early-Stopping + Checkpoint\n",
    "– tqdm-Balken auf Batch- und Epoch-Ebene\n",
    "– Argument-Parser ignoriert unbekannte Flags → funktioniert auch in Jupyter\n",
    "\n",
    "Getestet mit **Python 3.12**, `torch 2.2`, `torchvision 0.17`, `tqdm 4.66`.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ───────────────────────────── CLI ──────────────────────────────\n",
    "\n",
    "def parse_args(argv: list[str] | None = None) -> argparse.Namespace:\n",
    "    \"\"\"Ignoriert unbekannte Flags (Jupyter) & setzt Notebook-Defaults.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"CNN-Benchmark\")\n",
    "    parser.add_argument(\"--data_root\", type=Path, default=Path(\"Data\"), help=\"Ordner mit Train/ Test Unterordnern\")\n",
    "    parser.add_argument(\"--models\", nargs=\"*\", default=[\n",
    "        \"mobilenet_v2\", \"mobilenet_v3_large\", \"resnet18\", \"resnet34\", \"resnet50\", \"efficientnet_b0\", \"vgg16\"],\n",
    "                        help=\"Modellnamen\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=25)\n",
    "    parser.add_argument(\"--batch\", type=int, default=64)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    parser.add_argument(\"--patience\", type=int, default=5)\n",
    "    parser.add_argument(\"--val_split\", type=float, default=0.15)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    if argv is None and (\"ipykernel\" in sys.argv[0] or any(a.startswith(\"-f\") for a in sys.argv)):\n",
    "        # Notebook-Modus\n",
    "        args, _ = parser.parse_known_args([])\n",
    "    else:\n",
    "        args, _ = parser.parse_known_args(argv)\n",
    "    return args\n",
    "\n",
    "# ─────────────────────────── Helpers ────────────────────────────\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def compute_mean_std(ds):\n",
    "    loader = DataLoader(ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    mean = torch.zeros(3)\n",
    "    var = torch.zeros(3)\n",
    "    n = 0\n",
    "    for imgs, _ in tqdm(loader, desc=\"calc mean/std\", leave=False):\n",
    "        b = imgs.size(0)\n",
    "        imgs = imgs.view(b, 3, -1)\n",
    "        mean += imgs.mean(2).sum(0)\n",
    "        var += imgs.var(2).sum(0)\n",
    "        n += b\n",
    "    mean /= n\n",
    "    std = (var / n).sqrt()\n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "def make_sampler(targets):\n",
    "    counts = Counter(targets)\n",
    "    class_w = {c: 1 / cnt for c, cnt in counts.items()}\n",
    "    sample_w = [class_w[t] for t in targets]\n",
    "    return WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
    "\n",
    "# ───────────────────────── Model-Factory ────────────────────────\n",
    "\n",
    "def get_model(name: str, classes: int, pretrained=True):\n",
    "    name = name.lower()\n",
    "    if name == \"mobilenet_v2\":\n",
    "        w = models.MobileNet_V2_Weights.DEFAULT if pretrained else None\n",
    "        m = models.mobilenet_v2(weights=w)\n",
    "        m.classifier[1] = nn.Linear(m.classifier[1].in_features, classes)\n",
    "    elif name == \"mobilenet_v3_large\":\n",
    "        w = models.MobileNet_V3_Large_Weights.DEFAULT if pretrained else None\n",
    "        m = models.mobilenet_v3_large(weights=w)\n",
    "        m.classifier[3] = nn.Linear(m.classifier[3].in_features, classes)\n",
    "    elif name in {\"resnet18\", \"resnet34\", \"resnet50\"}:\n",
    "        w_enum = getattr(models, f\"{name.capitalize()}_Weights\")\n",
    "        w = w_enum.DEFAULT if pretrained else None\n",
    "        m = getattr(models, name)(weights=w)\n",
    "        m.fc = nn.Linear(m.fc.in_features, classes)\n",
    "    elif name == \"efficientnet_b0\":\n",
    "        w = models.EfficientNet_B0_Weights.DEFAULT if pretrained else None\n",
    "        m = models.efficientnet_b0(weights=w)\n",
    "        m.classifier[1] = nn.Linear(m.classifier[1].in_features, classes)\n",
    "    elif name == \"vgg16\":\n",
    "        w = models.VGG16_Weights.DEFAULT if pretrained else None\n",
    "        m = models.vgg16(weights=w)\n",
    "        m.classifier[6] = nn.Linear(m.classifier[6].in_features, classes)\n",
    "    else:\n",
    "        raise ValueError(name)\n",
    "    return m\n",
    "\n",
    "# ───────────────────────── Train / Val ──────────────────────────\n",
    "\n",
    "def run_epoch(model, loader, criterion, optimizer=None, device=\"cpu\", desc=\"train\"):\n",
    "    train = optimizer is not None\n",
    "    model.train() if train else model.eval()\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    true, pred = [], []\n",
    "    loop = tqdm(loader, desc=desc, leave=False)\n",
    "    for x, y in loop:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        p = out.argmax(1)\n",
    "        bs = y.size(0)\n",
    "        total += bs\n",
    "        correct += (p == y).sum().item()\n",
    "        loss_sum += loss.item() * bs\n",
    "        true.extend(y.cpu())\n",
    "        pred.extend(p.cpu())\n",
    "        loop.set_postfix(loss=loss_sum/total, acc=correct/total)\n",
    "    acc = correct/total\n",
    "    micro = f1_score(true, pred, average=\"micro\")\n",
    "    macro = f1_score(true, pred, average=\"macro\", zero_division=0)\n",
    "    return loss_sum/total, acc, micro, macro\n",
    "\n",
    "# ───────────────────────── Benchmark ────────────────────────────\n",
    "\n",
    "def benchmark(cfg):\n",
    "    set_seed(cfg.seed)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pin_memory = device.type == \"cuda\"\n",
    "\n",
    "    train_dir = cfg.data_root / \"Train\"\n",
    "    test_dir = cfg.data_root / \"Test\"\n",
    "    if not train_dir.exists():\n",
    "        raise FileNotFoundError(train_dir)\n",
    "\n",
    "    base_tf = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "    full_ds = datasets.ImageFolder(train_dir, transform=base_tf)\n",
    "    d_mean, d_std = compute_mean_std(full_ds)\n",
    "\n",
    "    v_len = int(len(full_ds)*cfg.val_split)\n",
    "    t_len = len(full_ds)-v_len\n",
    "    train_ds, val_ds = random_split(full_ds, [t_len, v_len], generator=torch.Generator().manual_seed(cfg.seed))\n",
    "    sampler = make_sampler([full_ds.targets[i] for i in train_ds.indices])\n",
    "\n",
    "    test_tf = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "    test_ds = datasets.ImageFolder(test_dir, transform=test_tf)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name in cfg.models:\n",
    "        print(\"\\n──\", name.upper(), \"──\")\n",
    "        pretrained = True  # fine-tuning-Pfad\n",
    "        norm_mean, norm_std = (IMAGENET_MEAN, IMAGENET_STD) if pretrained else (d_mean, d_std)\n",
    "\n",
    "        train_ds.dataset.transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(0.2,0.2,0.2),\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(norm_mean, norm_std)\n",
    "        ])\n",
    "        val_ds.dataset.transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(norm_mean, norm_std)\n",
    "        ])\n",
    "        test_ds.transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(norm_mean, norm_std)\n",
    "        ])\n",
    "\n",
    "        t_loader = DataLoader(train_ds, batch_size=cfg.batch, sampler=sampler, num_workers=2, pin_memory=pin_memory)\n",
    "        v_loader = DataLoader(val_ds, batch_size=cfg.batch, shuffle=False, num_workers=2, pin_memory=pin_memory)\n",
    "        test_loader = DataLoader(test_ds, batch_size=cfg.batch, shuffle=False, num_workers=2, pin_memory=pin_memory)\n",
    "\n",
    "        model = get_model(name, classes=len(full_ds.classes), pretrained=pretrained).to(device)\n",
    "        opt = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "        sched = optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.3, patience=3)\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "\n",
    "        best_acc, patience = 0.0, 0\n",
    "        ckpt = Path(f\"best_{name}.pt\")\n",
    "        for ep in tqdm(range(1, cfg.epochs+1), desc=\"epochs\", position=0):\n",
    "            run_epoch(model, t_loader, crit, optimizer=opt, device=device, desc=f\"train e{ep}\")\n",
    "            _, v_acc, _, _ = run_epoch(model, v_loader, crit, device=device, desc=f\"val   e{ep}\")\n",
    "            sched.step(v_acc)\n",
    "            if v_acc>best_acc:\n",
    "                best_acc = v_acc\n",
    "                patience = 0\n",
    "                torch.save(model.state_dict(), ckpt)\n",
    "            else:\n",
    "                patience +=1\n",
    "                if patience>=cfg.patience:\n",
    "                    print(\"early stop\")\n",
    "                    break\n",
    "\n",
    "        model.load_state_dict(torch.load(ckpt))\n",
    "        _, test_acc, micro, macro = run_epoch(model, test_loader, crit, device=device, desc=\"test\")\n",
    "        results[name] = test_acc\n",
    "        print(f\"Test-Acc {test_acc:.3f}  micro-F1 {micro:.3f}  macro-F1 {macro:.3f}\")\n",
    "\n",
    "    print(\"\\nSummary\")\n",
    "    for k,v in results.items():\n",
    "        print(f\"{k:20s}: {v:.3f}\")\n",
    "    best = max(results, key=results.get)\n",
    "    print(\"Best model:\", best, results[best])\n",
    "\n",
    "# ──────────────────────────── Main ─────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = parse_args()\n",
    "    benchmark(cfg)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "── MOBILENET_V2 ──\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 0/25 [00:00<?, ?it/s]\n",
      "train e1:   0%|          | 0/30 [00:00<?, ?it/s]\u001B[A\n",
      "train e1:   0%|          | 0/30 [00:08<?, ?it/s, acc=0.125, loss=2.2]\u001B[A\n",
      "train e1:   3%|▎         | 1/30 [00:08<04:01,  8.32s/it, acc=0.125, loss=2.2]\u001B[A\n",
      "train e1:   3%|▎         | 1/30 [00:13<04:01,  8.32s/it, acc=0.156, loss=2.17]\u001B[A\n",
      "train e1:   7%|▋         | 2/30 [00:13<02:59,  6.40s/it, acc=0.156, loss=2.17]\u001B[A\n",
      "train e1:   7%|▋         | 2/30 [00:18<02:59,  6.40s/it, acc=0.208, loss=2.12]\u001B[A\n",
      "train e1:  10%|█         | 3/30 [00:18<02:34,  5.72s/it, acc=0.208, loss=2.12]\u001B[A\n",
      "train e1:  10%|█         | 3/30 [00:23<02:34,  5.72s/it, acc=0.238, loss=2.08]\u001B[A\n",
      "train e1:  13%|█▎        | 4/30 [00:23<02:24,  5.56s/it, acc=0.238, loss=2.08]\u001B[A\n",
      "train e1:  13%|█▎        | 4/30 [00:28<02:24,  5.56s/it, acc=0.275, loss=2.03]\u001B[A\n",
      "train e1:  17%|█▋        | 5/30 [00:28<02:09,  5.19s/it, acc=0.275, loss=2.03]\u001B[A\n",
      "train e1:  17%|█▋        | 5/30 [00:32<02:09,  5.19s/it, acc=0.315, loss=1.97]\u001B[A\n",
      "train e1:  20%|██        | 6/30 [00:32<01:59,  4.99s/it, acc=0.315, loss=1.97]\u001B[AException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x12f099da0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aaron/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/aaron/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "\n",
      "epochs:   0%|          | 0/25 [00:38<?, ?it/s]                                \u001B[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 238\u001B[39m\n\u001B[32m    236\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    237\u001B[39m     cfg = parse_args()\n\u001B[32m--> \u001B[39m\u001B[32m238\u001B[39m     \u001B[43mbenchmark\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 211\u001B[39m, in \u001B[36mbenchmark\u001B[39m\u001B[34m(cfg)\u001B[39m\n\u001B[32m    209\u001B[39m ckpt = Path(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mbest_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.pt\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m ep \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m, cfg.epochs+\u001B[32m1\u001B[39m), desc=\u001B[33m\"\u001B[39m\u001B[33mepochs\u001B[39m\u001B[33m\"\u001B[39m, position=\u001B[32m0\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m211\u001B[39m     \u001B[43mrun_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcrit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtrain e\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mep\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    212\u001B[39m     _, v_acc, _, _ = run_epoch(model, v_loader, crit, device=device, desc=\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mval   e\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mep\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    213\u001B[39m     sched.step(v_acc)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 129\u001B[39m, in \u001B[36mrun_epoch\u001B[39m\u001B[34m(model, loader, criterion, optimizer, device, desc)\u001B[39m\n\u001B[32m    127\u001B[39m x, y = x.to(device), y.to(device)\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.set_grad_enabled(train):\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     out = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    130\u001B[39m     loss = criterion(out, y)\n\u001B[32m    131\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m train:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv2.py:174\u001B[39m, in \u001B[36mMobileNetV2.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m174\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv2.py:166\u001B[39m, in \u001B[36mMobileNetV2._forward_impl\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    163\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_forward_impl\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) -> Tensor:\n\u001B[32m    164\u001B[39m     \u001B[38;5;66;03m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001B[39;00m\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    167\u001B[39m     \u001B[38;5;66;03m# Cannot use \"squeeze\" as batch-size can be 1\u001B[39;00m\n\u001B[32m    168\u001B[39m     x = nn.functional.adaptive_avg_pool2d(x, (\u001B[32m1\u001B[39m, \u001B[32m1\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    218\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torchvision/models/mobilenetv2.py:62\u001B[39m, in \u001B[36mInvertedResidual.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) -> Tensor:\n\u001B[32m     61\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.use_res_connect:\n\u001B[32m---> \u001B[39m\u001B[32m62\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m x + \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     63\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     64\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.conv(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    218\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    218\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001B[39m, in \u001B[36mConv2d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    459\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m460\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/UniAufMac/Data/Cancer_Data_Collection/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001B[39m, in \u001B[36mConv2d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    452\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m'\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m'\u001B[39m:\n\u001B[32m    453\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(F.pad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode),\n\u001B[32m    454\u001B[39m                     weight, bias, \u001B[38;5;28mself\u001B[39m.stride,\n\u001B[32m    455\u001B[39m                     _pair(\u001B[32m0\u001B[39m), \u001B[38;5;28mself\u001B[39m.dilation, \u001B[38;5;28mself\u001B[39m.groups)\n\u001B[32m--> \u001B[39m\u001B[32m456\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  }
 ]
}
