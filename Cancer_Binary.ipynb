{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fKL-ubjNe-CH"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Zuerst stellen wir sicher, dass wir alle notwendigen Bibliotheken importieren:\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import helper\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9kVlCqHfk-W",
        "outputId": "e23fcd77-7d73-4d24-bcf7-a5a382918d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Simple Neural Network\n",
        "# Had to comment out the following lines to run the code locally\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8Arb7_tvflAw"
      },
      "outputs": [],
      "source": [
        "# Define the size of the individual images\n",
        "# and the batch size\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "       # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OZQuFIM0flDM"
      },
      "outputs": [],
      "source": [
        "# load dataset: https://www.kaggle.com/datasets/bhavikjikadara/dog-and-cat-classification-dataset\n",
        "data_dir = 'Data/Train'\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "# only load a subet because it's faster\n",
        "dataset_subset = torch.utils.data.Subset(dataset, np.random.choice(len(dataset), 100, replace=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsijwewAmAyJ",
        "outputId": "72d26380-d906-4efb-f117-fdc762f88ade"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tp8AG3xhRTJ"
      },
      "outputs": [],
      "source": [
        "# split the data\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset_subset, [0.8, 0.2])\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "x_uPLtDCflJQ",
        "outputId": "254e63ce-b398-410a-9cb6-1b4693fbaf83"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m6\u001b[39m):\n\u001b[32m      6\u001b[39m     plt.subplot(\u001b[32m2\u001b[39m,\u001b[32m3\u001b[39m,i+\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     plt.imshow((\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m.numpy() * \u001b[32m255\u001b[39m).astype(np.uint8))\n\u001b[32m      8\u001b[39m plt.show()\n",
            "\u001b[31mRuntimeError\u001b[39m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# look at one batch of images\n",
        "examples = iter(dataset_subset) # create iterable object\n",
        "samples, labels = next(examples)  # unpack the batch\n",
        "# make a plot\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow((samples[i].permute(1, 2, 0).numpy() * 255).astype(np.uint8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9c7DwAKh_5s",
        "outputId": "58e28a49-fcdf-403a-b75a-522aa3f893ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CustomCNNModel(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=9408, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Nun definieren wir unser eigenständiges CNN-Modell mit 3 Layern:\n",
        "\"\"\"\n",
        "# Definition des eigenen CNN-Modells\n",
        "class CustomCNNModel(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(CustomCNNModel, self).__init__()\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = torch.nn.Linear(3 * 56 * 56, num_classes, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Device configuration, Prüfe ob GPU verfügbar ist, falls ja, lasse das Modell auf eie GPU laufen, ansonsten CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CustomCNNModel(num_classes=2)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Nbq9lnUnOfp",
        "outputId": "a8da2c69-afcb-4593-c9e1-63b1a36e60ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CustomCNNModel(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=9408, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mad4QtwjPvO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Als nächstes definieren wir die Loss Function und den Optimizer:\n",
        "\"\"\"\n",
        "# Verlustfunktion und Optimierer definieren\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPLmtor2ilkk",
        "outputId": "1b9d5d9e-0210-4ad9-c793-07a65f844623"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.021, Acc: 0.615: 100%|██████████| 250/250 [13:02<00:00,  3.13s/it]\n",
            "Epoch [2/10], Loss: 0.020, Acc: 0.655: 100%|██████████| 250/250 [00:44<00:00,  5.64it/s]\n",
            "Epoch [3/10], Loss: 0.019, Acc: 0.670: 100%|██████████| 250/250 [00:45<00:00,  5.46it/s]\n",
            "Epoch [4/10], Loss: 0.019, Acc: 0.695: 100%|██████████| 250/250 [00:44<00:00,  5.57it/s]\n",
            "Epoch [5/10], Loss: 0.018, Acc: 0.705: 100%|██████████| 250/250 [00:43<00:00,  5.69it/s]\n",
            "Epoch [6/10], Loss: 0.017, Acc: 0.719: 100%|██████████| 250/250 [00:46<00:00,  5.36it/s]\n",
            "Epoch [7/10], Loss: 0.016, Acc: 0.742: 100%|██████████| 250/250 [00:45<00:00,  5.53it/s]\n",
            "Epoch [8/10], Loss: 0.015, Acc: 0.768: 100%|██████████| 250/250 [00:47<00:00,  5.29it/s]\n",
            "Epoch [9/10], Loss: 0.014, Acc: 0.786: 100%|██████████| 250/250 [00:45<00:00,  5.54it/s]\n",
            "Epoch [10/10], Loss: 0.013, Acc: 0.805: 100%|██████████| 250/250 [00:44<00:00,  5.61it/s]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Trainieren des Modells\n",
        "\"\"\"\n",
        "# Trainingsschleife\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    running_samples = 0\n",
        "    pbar = tqdm(train_loader)\n",
        "    nr_samples = 0\n",
        "    for idx, (images, labels) in enumerate(pbar, start=1):\n",
        "        # Vorhersage und Verlust berechnen\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Gradienten zurücksetzen, Backwardpropagation und Optimierung\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        nr_samples += images.shape[0]\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_corrects += torch.sum(preds == labels)\n",
        "        cnt_acc = running_corrects/nr_samples\n",
        "        cnt_loss = running_loss/nr_samples\n",
        "        pbar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Loss: {cnt_loss:.3f}, Acc: {cnt_acc:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68ZyJRJoilpI",
        "outputId": "df9dc6a3-c717-40b0-c80b-19ab68c44c0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [05:05<00:00,  9.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on Test dataset: 62.500 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "errors = []\n",
        "model.eval()\n",
        "running_corrects = 0\n",
        "nr_samples = 0\n",
        "for images, labels in tqdm(test_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    running_corrects += torch.sum(preds == labels)\n",
        "    nr_samples += images.shape[0]\n",
        "    #if preds != labels:\n",
        "    #  errors.append({\"image\":images.to(\"cpu\")[0], \"y_hat\":preds.to(\"cpu\")[0].item(), \"label\":labels.to(\"cpu\")[0].item()})\n",
        "print()\n",
        "print(f\"Accuracy on Test dataset: {(running_corrects/nr_samples)*100:.3f} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "TMSiFF7Dy7B6",
        "outputId": "fdf29f83-6bbd-4b3c-e591-45a7ef923984"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6b9366e85b90>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Label: {errors[idx]['label']}, Prediction: {errors[idx]['y_hat']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# Show some errors\n",
        "idx = 1\n",
        "print(f\"Label: {errors[idx]['label']}, Prediction: {errors[idx]['y_hat']}\")\n",
        "plt.imshow((errors[idx]['image'].permute(1, 2, 0).numpy() * 255).astype(np.uint8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZeQOeoZy7E-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
